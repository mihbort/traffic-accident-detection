{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/media/misha/Data/Game Captures GTA/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(folder + '0-country-test.mov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "kernel = np.ones((3,3),np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "1. Preproces:\n",
    "    - Convert to Gray\n",
    "    - Downscale\n",
    "    - Blur\n",
    "2. BGS using GMM\n",
    "3. Find moving objects and track\n",
    "4. Extract movement features\n",
    "5. Classify them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: how to initialize mean-shift tracking\n",
    "\n",
    "see: Vehicle tracking by non-drifting mean-shift using projective Kalman filter https://pdfs.semanticscholar.org/c4b0/18193f813eaa8981ee4e85657669e5865fab.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BGS GMM + Morph_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "r,h,c,w = 100,90,200,125  # simply hardcoded the values\n",
    "track_window = (c,r,w,h)\n",
    "\n",
    "# set up the ROI for tracking\n",
    "roi = frame[r:r+h, c:c+w]\n",
    "hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "mask = cv2.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
    "roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "# Setup the termination criteria, either 10 iteration or move by atleast 1 \n",
    "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the termination criteria, either 10 iteration or move by atleast 1 \n",
    "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessFrame(frame):\n",
    "#     frame = cv2.resize(frame, (640, 360), interpolation=cv2.INTER_AREA)\n",
    "    frame_bw = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_bw = cv2.GaussianBlur(frame_bw, (21, 21), 0)\n",
    "    return frame_bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test begin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(folder + '0-country-test.mov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, frame = cap.read()\n",
    "frame = cv2.resize(frame, (640, 360), interpolation=cv2.INTER_AREA)\n",
    "frame_bw = preprocessFrame(frame)\n",
    "fgmask = fgbg.apply(frame_bw)\n",
    "flt_fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "flt_fgmask = cv2.threshold(flt_fgmask, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "flt_fgmask = cv2.dilate(flt_fgmask, None, iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "cnts = cv2.findContours(flt_fgmask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_old_cnts0 = []\n",
    "old_cnts0 = []\n",
    "\n",
    "super_old_cnts1 = []\n",
    "old_cnts1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_old_cnts0 = [None]*len(cnts)\n",
    "old_cnts0 = [None]*len(cnts)\n",
    "super_old_cnts0[0] = cv2.boundingRect(cnts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(super_old_cnts0)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-dd8617575643>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x,y,w,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y,w,h) = super_old_cnts0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(438, 94, 21, 20)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_old_cnts0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-15b0911dd40f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalcBackProject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhsv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mroi_hist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack_window\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeanShift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_crit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mold_cnts0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrack_window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "(x,y,w,h) = super_old_cnts0[0]\n",
    "roi = frame[y:y+h, x:x+w]\n",
    "hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "mask = cv2.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
    "roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "ret, track_window = cv2.meanShift(dst, (x,y,w,h), term_crit)\n",
    "old_cnts0[0] = track_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[448,  94]],\n",
       "\n",
       "       [[447,  95]],\n",
       "\n",
       "       [[446,  95]],\n",
       "\n",
       "       [[445,  96]],\n",
       "\n",
       "       [[444,  96]],\n",
       "\n",
       "       [[442,  98]],\n",
       "\n",
       "       [[441,  98]],\n",
       "\n",
       "       [[441,  99]],\n",
       "\n",
       "       [[440, 100]],\n",
       "\n",
       "       [[440, 101]],\n",
       "\n",
       "       [[438, 103]],\n",
       "\n",
       "       [[438, 109]],\n",
       "\n",
       "       [[439, 110]],\n",
       "\n",
       "       [[440, 110]],\n",
       "\n",
       "       [[442, 112]],\n",
       "\n",
       "       [[444, 112]],\n",
       "\n",
       "       [[445, 113]],\n",
       "\n",
       "       [[454, 113]],\n",
       "\n",
       "       [[456, 111]],\n",
       "\n",
       "       [[456, 110]],\n",
       "\n",
       "       [[457, 109]],\n",
       "\n",
       "       [[457, 104]],\n",
       "\n",
       "       [[458, 103]],\n",
       "\n",
       "       [[458,  97]],\n",
       "\n",
       "       [[457,  96]],\n",
       "\n",
       "       [[457,  95]],\n",
       "\n",
       "       [[456,  94]]], dtype=int32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (x, y, w, h)\n",
    "super_old_cnts0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(305, 231, 9, 9) (304, 230, 9, 9) (304, 230, 9, 9) 0.0 1.4142135623730951\n",
      "(320, 218, 8, 7) (319, 217, 8, 7) (319, 218, 8, 7) 1.0 1.4142135623730951\n",
      "(365, 202, 14, 8) (363, 202, 14, 8) (364, 202, 14, 8) 1.0 2.0\n",
      "(325, 213, 8, 8) (325, 212, 8, 8) (325, 212, 8, 8) 0.0 1.0\n",
      "(378, 188, 14, 11) (378, 188, 14, 11) (378, 187, 14, 11) 1.0 0.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-7df98ac7edce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# update frames for alternative thread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper_old_cnts1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper_old_cnts1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0mroi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mhsv_roi\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2HSV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "# ret, frame = cap.read()\n",
    "# fgmask = fgbg.apply(frame)\n",
    "cap = cv2.VideoCapture(folder + '0-country-test.mov')\n",
    "fr_number = 0\n",
    "# super_old_cnts0 = []\n",
    "# old_cnts0 = []\n",
    "\n",
    "# super_old_cnts1 = []\n",
    "# old_cnts1 = []\n",
    "\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame, (640, 360), interpolation=cv2.INTER_AREA)\n",
    "    frame_bw = preprocessFrame(frame)\n",
    "    fgmask = fgbg.apply(frame_bw)\n",
    "    flt_fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "    flt_fgmask = cv2.threshold(flt_fgmask, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "    flt_fgmask = cv2.dilate(flt_fgmask, None, iterations=2)\n",
    "    \n",
    "\n",
    "#     track some window...\n",
    "    \n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    \n",
    "#     ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
    "#     x,y,w,h = track_window\n",
    "#     img2 = cv2.rectangle(frame, (x,y), (x+w,y+h), 255,2)\n",
    "    \n",
    "#     ret, track_window2 = cv2.meanShift(dst, (x2, y2, w2, h2), term_crit)\n",
    "#     x2,y2,w2,h2 = track_window2\n",
    "#     cv2.rectangle(img2, (x2, y2), (x2 + w2, y2 + h2), (255, 255, 0), 2)\n",
    "    \n",
    "    cnts = cv2.findContours(flt_fgmask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n",
    "    \n",
    "    # Now we have new good contours and need to run tracking:\n",
    "    \n",
    "    if fr_number % 2 == 0:\n",
    "        # calc for the third frame:\n",
    "        for i in range(len(old_cnts0)):\n",
    "            if old_cnts0[0] == None: continue\n",
    "            (x,y,w,h) = super_old_cnts0[i]\n",
    "            roi = frame[y:y+h, x:x+w]\n",
    "            hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "            mask = cv2.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
    "            roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "            cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "            dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "            ret, track_window = cv2.meanShift(dst, (x,y,w,h), term_crit)\n",
    "            \n",
    "        \n",
    "            # calc acc and speed\n",
    "            print(super_old_cnts0[i], old_cnts0[i], track_window, \n",
    "                  math.sqrt((old_cnts0[i][0] - track_window[0])**2 + (old_cnts0[i][1] - track_window[1])**2),\n",
    "                 math.sqrt((super_old_cnts0[i][0] - old_cnts0[i][0])**2 + (super_old_cnts0[i][1] - old_cnts0[i][1])**2))\n",
    "        # make all containers null\n",
    "        super_old_cnts0 = [None]*len(cnts)\n",
    "        old_cnts0 = [None]*len(cnts)\n",
    "        # record new frame\n",
    "        for i in range(len(cnts)):\n",
    "            super_old_cnts0[i] = cv2.boundingRect(cnts[i])\n",
    "        \n",
    "        # update frames for alternative thread\n",
    "        for i in range(len(super_old_cnts1)):\n",
    "            (x,y,w,h) = super_old_cnts1[i]\n",
    "            roi = frame[y:y+h, x:x+w]\n",
    "            hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "            mask = cv2.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
    "            roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "            cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "            dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "            ret, track_window = cv2.meanShift(dst, (x,y,w,h), term_crit)\n",
    "            \n",
    "            old_cnts1[i] = track_window\n",
    "        \n",
    "        \n",
    "    else: # Fix me\n",
    "        super_old_cnts1 = cnts\n",
    "        # update second frame\n",
    "        for i in range(len(super_old_cnts0)):\n",
    "            \n",
    "            (x,y,w,h) = super_old_cnts0[i]\n",
    "            roi = frame[y:y+h, x:x+w]\n",
    "            hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "            mask = cv2.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
    "            roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "            cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "            dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "            ret, track_window = cv2.meanShift(dst, super_old_cnts0[i], term_crit)\n",
    "            old_cnts0[i] = track_window\n",
    "    \n",
    "        # calculate third value and classify\n",
    "    \n",
    "    \n",
    "#     for i in range(len(old_cnts)):\n",
    "#         ret, track_window = cv2.meanShift(dst, old_cnts[i], term_crit)\n",
    "#         print(old_cnts[i], track_window, \n",
    "#               math.sqrt((old_cnts[i][0] - track_window[0])**2 + (old_cnts[i][1] - track_window[1])**2),\n",
    "#              math.sqrt((super_old_cnts[i][0] - old_cnts[i][0])**2 + (super_old_cnts[i][1] - old_cnts[i][1])**2))\n",
    "    \n",
    "#     for i in range(len(cnts)):\n",
    "#         old_cnts.append(cv2.boundingRect(cnts[i]))\n",
    "#         x,y,w,h = old_cnts[i]\n",
    "#         cv2.rectangle(img2, (x,y), (x+w,y+h), (0, 255, i), 2)\n",
    "    \n",
    "    \n",
    "    for c in cnts:\n",
    "        if cv2.contourArea(c) < 50:\n",
    "            continue\n",
    "\n",
    "            # compute the bounding box for the contour, draw it on the frame,\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        \n",
    "#         ret, track_window = cv2.meanShift(dst,  (x, y, w, h), term_crit)\n",
    "        \n",
    "#         cv2.rectangle(img2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "        \n",
    "        \n",
    "#     if fr_number % 100 == 0:\n",
    "#         track_window = (x, y, w, h)\n",
    "        \n",
    "    \n",
    "    cv2.imshow('mask',flt_fgmask)\n",
    "    cv2.imshow('frame',frame)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    \n",
    "    fr_number += 1\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None]\n"
     ]
    }
   ],
   "source": [
    "print(old_cnts0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(old_cnts0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cnts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(old_cnts)):\n",
    "        ret, track_window = cv2.meanShift(dst, old_cnts[i], term_crit)\n",
    "        print(old_cnts[i], track_window, \n",
    "              math.sqrt((old_cnts[i][0] - track_window[0])**2 + (old_cnts[i][1] - track_window[1])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, track_window = cv2.meanShift(dst, cv2.boundingRect(cnts[0]), term_crit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, track_window = cv2.meanShift(dst, cv2.boundingRect(cnts[0]), term_crit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:5],y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.boundingRect(cnts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for i in range(len(cnts[0])):\n",
    "    x.append(cnts[0][i][0][0])\n",
    "    y.append(cnts[0][i][0][1])\n",
    "#     print(cnts[i][0][0][0])\n",
    "plt.scatter(x,y)\n",
    "# plt.imshow(fgmask)\n",
    "plt.imshow(frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "print(len(cnts))\n",
    "for c in cntrs:\n",
    "#     print(center[0][0])\n",
    "    x.append(center[0][0][0])\n",
    "    y.append(center[0][0][1])\n",
    "#     plt.plot(center[0][0])\n",
    "plt.scatter(x,y)\n",
    "# plt.imshow(fgmask)\n",
    "plt.imshow(frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(fgmask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(folder + '1-highway-test.mov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame, (640, 360), interpolation=cv2.INTER_AREA)\n",
    "    fgmask = fgbg.apply(preprocessFrame(frame))\n",
    "\n",
    "    flt_fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "    flt_fgmask = cv2.threshold(flt_fgmask, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "    flt_fgmask = cv2.dilate(flt_fgmask, None, iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fgmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cntrs = detect_vehicles(flt_fgmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "print(len(cnts))\n",
    "for center in cntrs:\n",
    "#     print(center[0][0])\n",
    "    x.append(center[0][0][0])\n",
    "    y.append(center[0][0][1])\n",
    "#     plt.plot(center[0][0])\n",
    "plt.scatter(x,y)\n",
    "# plt.imshow(fgmask)\n",
    "plt.imshow(frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are contours\n",
    "cv2.findContours(), cv2.drawContours()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroid(x, y, w, h):\n",
    "    x1 = int(w / 2)\n",
    "    y1 = int(h / 2)\n",
    "\n",
    "    cx = x + x1\n",
    "    cy = y + y1\n",
    "\n",
    "    return (cx, cy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_vehicles(fg_mask, min_contour_width=35, min_contour_height=35):\n",
    "\n",
    "    matches = []\n",
    "\n",
    "    # finding external contours\n",
    "    im, contours, hierarchy = cv2.findContours(\n",
    "        fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_TC89_L1)\n",
    "\n",
    "    # filtering by with, height\n",
    "    for (i, contour) in enumerate(contours):\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        contour_valid = (w >= min_contour_width) and (\n",
    "            h >= min_contour_height)\n",
    "\n",
    "        if not contour_valid:\n",
    "            continue\n",
    "        \n",
    "        # getting center of the bounding box\n",
    "        centroid = get_centroid(x, y, w, h)\n",
    "\n",
    "        matches.append(((x, y, w, h), centroid))\n",
    "\n",
    "#     return matches\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.dilate(thresh, None, iterations=2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(flt_fgmask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = cv2.threshold(fgmask, 25, 255, cv2.THRESH_BINARY)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnts = cv2.findContours(flt_fgmask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cnts:\n",
    "    if cv2.contourArea(c) < 50:\n",
    "        continue\n",
    " \n",
    "        # compute the bounding box for the contour, draw it on the frame,\n",
    "        # and update the text\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    text = \"Occupied\"\n",
    "    print(cv2.contourArea(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cnts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, frame = cap.read()\n",
    "fgmask = fgbg.apply(frame)\n",
    "car_boxes = detect_vehicles(fgmask)\n",
    "print(car_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(car_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx = car_boxes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fgmask,cmap='gray')\n",
    "for box in car_boxes:\n",
    "    px = plt.plot(box[1])\n",
    "    plt.setp(px, linewidth=10, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, elem in enumerate(car_boxes):\n",
    "    if elem.shape[0] > 35:\n",
    "        print('lolololololololololololo', i)\n",
    "        print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(car_boxes[110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(car_boxes[110])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
